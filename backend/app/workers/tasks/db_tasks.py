from app.workers.celery_app import celery_app
from app.db.session import AsyncSessionLocal
from app.models.fraud import FraudulentNumber, FraudType
from app.models.report import DetectionLog
from app.services.cache import cache_service
from datetime import datetime, timedelta
from sqlalchemy import delete
import logging
import httpx

logger = logging.getLogger(__name__)


@celery_app.task(name="app.workers.tasks.db_tasks.sync_external_frauds")
def sync_external_frauds():
    """
    Synchroniser avec base de donn√©es externe de fraudes

    Ex√©cut√© : Toutes les 5 minutes
    Sources possibles :
    - API partenaires
    - CSV publics
    - Scraping sites gouvernementaux
    """

    logger.info("üîÑ Synchronisation base fraudes externe...")

    # Exemple : r√©cup√©rer depuis API partenaire
    try:
        # √Ä impl√©menter : appel API r√©el
        # response = httpx.get("https://fraud-db.example.com/api/latest")
        # new_frauds = response.json()

        # Pour MVP : simulation
        new_frauds = []

        logger.info(f"‚úÖ {len(new_frauds)} nouvelles fraudes synchronis√©es")

        return {
            "success": True,
            "new_frauds": len(new_frauds),
            "timestamp": str(datetime.utcnow())
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur sync fraudes: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@celery_app.task(name="app.workers.tasks.db_tasks.cleanup_cache")
def cleanup_cache():
    """
    Nettoyer cache Redis (entr√©es expir√©es)

    Ex√©cut√© : Toutes les heures
    """

    logger.info("üßπ Nettoyage cache Redis...")

    try:
        # Redis expire automatiquement les cl√©s avec TTL
        # Cette task peut faire du m√©nage suppl√©mentaire si besoin

        logger.info("‚úÖ Cache nettoy√©")

        return {
            "success": True,
            "timestamp": str(datetime.utcnow())
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage cache: {e}")
        return {"success": False, "error": str(e)}


@celery_app.task(name="app.workers.tasks.db_tasks.cleanup_old_logs")
def cleanup_old_logs():
    """
    Supprimer anciens logs de d√©tection (> 90 jours)

    Ex√©cut√© : Tous les jours √† 3h du matin
    Garde seulement les 90 derniers jours pour √©conomiser espace
    """

    logger.info("üßπ Nettoyage anciens logs...")

    async def _cleanup():
        async with AsyncSessionLocal() as db:
            cutoff_date = datetime.utcnow() - timedelta(days=90)

            result = await db.execute(
                delete(DetectionLog).where(
                    DetectionLog.timestamp < cutoff_date
                )
            )

            await db.commit()
            return result.rowcount

    try:
        import asyncio
        deleted = asyncio.run(_cleanup())

        logger.info(f"‚úÖ {deleted} anciens logs supprim√©s")

        return {
            "success": True,
            "deleted_logs": deleted,
            "timestamp": str(datetime.utcnow())
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage logs: {e}")
        return {"success": False, "error": str(e)}


@celery_app.task(name="app.workers.tasks.db_tasks.backup_database")
def backup_database():
    """
    Backup base de donn√©es (snapshot)

    Ex√©cut√© : Tous les jours √† 4h du matin
    """

    logger.info("üíæ Backup base de donn√©es...")

    try:
        # √Ä impl√©menter : pg_dump ou autre solution

        logger.info("‚úÖ Backup cr√©√©")

        return {
            "success": True,
            "timestamp": str(datetime.utcnow())
        }

    except Exception as e:
        logger.error(f"‚ùå Erreur backup: {e}")
        return {"success": False, "error": str(e)}
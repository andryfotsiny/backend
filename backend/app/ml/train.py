"""
Script d'entraÃ®nement des modÃ¨les ML pour DYLETH
EntraÃ®ne RandomForest pour classification SMS frauduleux
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import joblib
import os
from pathlib import Path

# Chemins
BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = BASE_DIR / "data" / "datasets"
MODEL_DIR = BASE_DIR / "models" / "ml_models"

# CrÃ©er dossiers si nÃ©cessaire
MODEL_DIR.mkdir(parents=True, exist_ok=True)

def train_sms_classifier():
    """EntraÃ®ne le classifieur SMS"""
    print("=" * 60)
    print("ğŸ¤– ENTRAÃNEMENT MODÃˆLE SMS DYLETH")
    print("=" * 60)

    # 1. Charger donnÃ©es
    print("\nğŸ“Š Chargement donnÃ©es...")
    df = pd.read_csv(DATA_DIR / "sms_train.csv")
    print(f"   âœ“ {len(df)} SMS chargÃ©s")
    print(f"   âœ“ Frauduleux: {df['is_fraud'].sum()} ({df['is_fraud'].sum()/len(df)*100:.1f}%)")
    print(f"   âœ“ LÃ©gitimes: {(~df['is_fraud'].astype(bool)).sum()} ({(~df['is_fraud'].astype(bool)).sum()/len(df)*100:.1f}%)")

    # 2. PrÃ©paration donnÃ©es
    print("\nğŸ”§ PrÃ©paration features...")
    X = df['content']
    y = df['is_fraud']

    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"   âœ“ Train: {len(X_train)} SMS")
    print(f"   âœ“ Test: {len(X_test)} SMS")

    # 3. Vectorisation TF-IDF
    print("\nğŸ“ Vectorisation TF-IDF...")
    vectorizer = TfidfVectorizer(
        max_features=1000,
        ngram_range=(1, 2),
        min_df=2,
        stop_words=None  # On garde tout pour le franÃ§ais
    )

    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)
    print(f"   âœ“ {X_train_tfidf.shape[1]} features extraites")

    # 4. EntraÃ®nement Random Forest
    print("\nğŸŒ² EntraÃ®nement Random Forest...")
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1,
        verbose=0
    )

    model.fit(X_train_tfidf, y_train)
    print("   âœ“ ModÃ¨le entraÃ®nÃ©")

    # 5. Ã‰valuation
    print("\nğŸ“ˆ Ã‰valuation modÃ¨le...")
    y_pred = model.predict(X_test_tfidf)
    y_proba = model.predict_proba(X_test_tfidf)

    accuracy = accuracy_score(y_test, y_pred)
    print(f"   âœ“ Accuracy: {accuracy*100:.2f}%")

    # Rapport dÃ©taillÃ©
    print("\nğŸ“Š Rapport classification:")
    print(classification_report(y_test, y_pred,
                                target_names=['LÃ©gitimes', 'Frauduleux'],
                                digits=3))

    # Matrice de confusion
    print("ğŸ”¢ Matrice de confusion:")
    cm = confusion_matrix(y_test, y_pred)
    print(f"   Vrais NÃ©gatifs:  {cm[0][0]}")
    print(f"   Faux Positifs:   {cm[0][1]}")
    print(f"   Faux NÃ©gatifs:   {cm[1][0]}")
    print(f"   Vrais Positifs:  {cm[1][1]}")

    # 6. Features importantes
    print("\nğŸ” Top 10 mots-clÃ©s frauduleux:")
    feature_names = vectorizer.get_feature_names_out()
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1][:10]

    for i, idx in enumerate(indices, 1):
        print(f"   {i}. '{feature_names[idx]}' - {importances[idx]:.4f}")

    # 7. Test sur exemples
    print("\nğŸ§ª Tests sur exemples:")
    test_messages = [
        "URGENT! Payez 2â‚¬ maintenant bit.ly",
        "Salut, Ã§a va? On se voit ce soir?",
        "Votre compte bancaire sera bloquÃ©",
        "RDV dentiste demain 14h"
    ]

    for msg in test_messages:
        features = vectorizer.transform([msg])
        pred = model.predict(features)[0]
        proba = model.predict_proba(features)[0]
        emoji = "ğŸš¨" if pred == 1 else "âœ…"
        print(f"   {emoji} '{msg[:40]}...'")
        print(f"      â†’ {'FRAUDE' if pred == 1 else 'LÃ‰GITIME'} (confiance: {proba[pred]:.2%})")

    # 8. Sauvegarder modÃ¨les
    print("\nğŸ’¾ Sauvegarde modÃ¨les...")
    joblib.dump(model, MODEL_DIR / "sms_model.pkl")
    joblib.dump(vectorizer, MODEL_DIR / "vectorizer.pkl")
    print(f"   âœ“ ModÃ¨le sauvegardÃ©: {MODEL_DIR / 'sms_model.pkl'}")
    print(f"   âœ“ Vectorizer sauvegardÃ©: {MODEL_DIR / 'vectorizer.pkl'}")

    # 9. MÃ©tadonnÃ©es
    metadata = {
        'accuracy': float(accuracy),
        'n_samples_train': len(X_train),
        'n_samples_test': len(X_test),
        'n_features': X_train_tfidf.shape[1],
        'model_type': 'RandomForestClassifier',
        'version': '1.0'
    }

    joblib.dump(metadata, MODEL_DIR / "sms_metadata.pkl")
    print(f"   âœ“ MÃ©tadonnÃ©es sauvegardÃ©es")

    print("\n" + "=" * 60)
    print(f"âœ… ENTRAÃNEMENT TERMINÃ‰ - Accuracy: {accuracy*100:.2f}%")
    print("=" * 60)

    return model, vectorizer, accuracy


def train_phone_classifier():
    """EntraÃ®ne le classifieur tÃ©lÃ©phone (simple pour MVP)"""
    print("\nğŸ“ EntraÃ®nement modÃ¨le tÃ©lÃ©phone...")
    print("   âš ï¸  Pour MVP: utilisation rÃ¨gles + base de donnÃ©es")
    print("   â„¹ï¸  ML tÃ©lÃ©phone sera entraÃ®nÃ© en Phase 2")


if __name__ == "__main__":
    print("\n" + "ğŸš€" * 30)
    print("   DYLETH - ML Training Pipeline")
    print("ğŸš€" * 30 + "\n")

    # VÃ©rifier que les datasets existent
    if not (DATA_DIR / "sms_train.csv").exists():
        print("âŒ Erreur: sms_train.csv introuvable")
        print(f"   CherchÃ© dans: {DATA_DIR}")
        exit(1)

    # EntraÃ®ner SMS (prioritÃ© 1)
    model, vectorizer, accuracy = train_sms_classifier()

    # TÃ©lÃ©phone (phase 2)
    train_phone_classifier()

    print("\nâœ… Tous les modÃ¨les sont prÃªts!")
    print("\nğŸ’¡ Prochaine Ã©tape:")
    print("   1. RedÃ©marrer l'API: uvicorn app.main:app --reload")
    print("   2. Tester: curl -X POST http://localhost:8000/api/v1/sms/analyze-sms")
    print("")